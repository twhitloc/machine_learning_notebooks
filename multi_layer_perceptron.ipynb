{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40a7e56-f4eb-4541-8a58-fa9450e45776",
   "metadata": {},
   "source": [
    "# The Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637025ab-74e8-48bc-b116-f19039025bf8",
   "metadata": {},
   "source": [
    "## Fully Connected Feed Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4faa7-757c-41a4-9924-7e6d2dbf7255",
   "metadata": {},
   "source": [
    "### The Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ff2b2-a382-473c-966f-c369b2e00161",
   "metadata": {},
   "source": [
    "Perceptrons are a part of a class of algorithms known as Artificial Neural Networks and they exist inside of the Deep Learning Paradigm, where features and functions are learned by these Artificial Neural Networks from large datasets.  As opposed to traditional Machine Learning approaches the amount of feature engineering and design are drastically reduced as the data structure will internally model these during the training phase.\n",
    "\n",
    "These algorithms use densely connected layers of weights, which are NxM matrices of real numbers, to multiply with the input parameters, the independent variables to predict the labeled outcome which is the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc90db0-ed5e-46df-b041-8ee59c5f08ea",
   "metadata": {},
   "source": [
    "These calculations are performed by stacking together these calculations, passing the output of one layer as the inputs into another layer, through a process known as feed forward.  Once these input variables are multiplied by the individual weights in a given layer, by a process known as dot product, or matrix multiplication, they are then passed into what is known as an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579e82a-5094-4cd2-bbf9-3b6d99cf505b",
   "metadata": {},
   "source": [
    "Activation Functions are non-linear functions that when multiplied by these vector sums produce what is known as an activation bump.  These functions are specifically non-linear primarily because this allows the networks to model very sophisticated functions and mappings through a process known as back-propagation.  This is the process by which the cost / error function is passed back through these series of layers to modify the individual weights and biases such that the error between the prediction and the true label is minimized over time, which allows the data structure to model the underlying latent space between these examples. In other words some prototypical features or representations that define this example space represented by the data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52478954-c9ff-47dc-9bd1-944bfd252b42",
   "metadata": {},
   "source": [
    "## Activation Functions:\n",
    "\n",
    "* Sigmoid : outputs values between 0, 1\n",
    "* Tanh : Outputs  values between -1, 1\n",
    "* Relu : Outputs values between 0, Infinity\n",
    "\n",
    "* The non-linearity allows for more complex functions to represent the space / plane that separates the class distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb086dc6-bed3-48a4-98bd-4c2d6e4cfc1d",
   "metadata": {},
   "source": [
    "## Perceptron is composed of these Stages:\n",
    "* Input (Any transformations on the raw data)\n",
    "* Weights (An NxM Matrix of coefficients to multiply the the input by)\n",
    "* Sum (Weights get added to any bias terms to reduce the likelihood of overfitting)\n",
    "* Non-Linearity (The resulting Matrix sum (Weights + Biases) is multiplied by a Non-Linear Activation Function)\n",
    "* Output (Classification Probability Predictions or Continuous Value Predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2026e-0a86-4aa0-b8bc-b5eccdd2752b",
   "metadata": {},
   "source": [
    "### Links to resources, tutorials:\n",
    "* https://keras.io/examples/vision/mlp_image_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769c8a2f-6f9b-4e67-a046-2961852ff342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6436eb72-cb23-49a4-aba8-a3ba1382bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2bdf99c-30ef-4a5b-8e6d-3c4b779f43df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 64 X 64 = 4096\n",
      "Patch size: 8 X 8 = 64 \n",
      "Patches per image: 64\n",
      "Elements per patch (3 channels): 192\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 0.0001\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "dropout_rate = 0.2\n",
    "image_size = 64  # We'll resize input images to this size.\n",
    "patch_size = 8  # Size of the patches to be extracted from the input images.\n",
    "num_patches = (image_size // patch_size) ** 2  # Size of the data array.\n",
    "embedding_dim = 256  # Number of hidden units.\n",
    "num_blocks = 4  # Number of blocks.\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
    "print(f\"Patches per image: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebd703-2187-4dce-bf0c-c256efb9b286",
   "metadata": {},
   "source": [
    "## Keras Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce74106-a0de-4914-b55e-5564027b4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_keras_classifier(blocks, \n",
    "                           positional_encoding=False):\n",
    "    \n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # Create image patches / sub-images\n",
    "    patches = Patches(patch_size, num_patches)(augmented)\n",
    "    \n",
    "    # Encode image patches to create a tensor\n",
    "    x = layers.Dense(units=embedding_dim)(patches)\n",
    "    \n",
    "    # Add the positional embeddings to the image patches\n",
    "    if positional_encoding:\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        position_embedding = layers.Embedding(input_dim=num_patches, output_dim=embedding_dim)(positions)\n",
    "        x = x + position_embedding\n",
    "    \n",
    "    # Process the encoded input using the Neural Network Blocks\n",
    "    x = blocks(x)\n",
    "    \n",
    "    # Apply global average pooling downsample representation\n",
    "    representation = layers.GlobalAvgPool1D()(x)\n",
    "    \n",
    "    # Apploy dropout to prevent overfitting\n",
    "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
    "    \n",
    "    # Compute logits, these are the units that lead into a softmax classifier\n",
    "    logits = layers.Dense(units=num_classes)(representation)\n",
    "    \n",
    "    return keras.Model(inputs=inputs, outputs=logits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eed5a8-7426-49f1-a5dd-04b67f741c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    # Create the optimizer with weight decay, this will perform : weights * (2* (Sum of Squares * weight_decay))\n",
    "    # Described here https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate,\n",
    "                                     weight_decay=weight_decay)\n",
    "    \n",
    "    # Compile the model using the optimizer, metrics and loss\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[keras.metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "                           keras.metrics.SparseTopKCategoricalAccuracy(name='top5-acc')])\n",
    "    \n",
    "    # Create a learning rate schedule callback to slowly dip the learning rate as epochs go on, to help with finding minima\n",
    "    learning_rate_schedule = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "    \n",
    "    # Create early stopping callback to prevent overfitting by stopping early and choosing the best weights\n",
    "    early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    # Fit the model on the dataset using the Optimizer, Loss Function, and other hyperparameters, IE: batch_size, epochs\n",
    "    record = model.fit(x=x_train,\n",
    "                       y=y_train,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       validation_split=0.1,\n",
    "                       callbacks=[early_stopping_callback,\n",
    "                                  learning_rate_schedule])\n",
    "    \n",
    "    _, score, top_5_score = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(score * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_score * 100, 2)}%\")\n",
    "\n",
    "    # Return history to plot learning curves.\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca611026-979c-41e1-896f-de3a649cefb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-27 14:43:47.016500: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "augmentations=[layers.Normalization(),\n",
    "               layers.Resizing(image_size, image_size),\n",
    "               layers.RandomFlip('horizontal'),\n",
    "               layers.RandomZoom(height_factor=.2, width_factor=.2)]\n",
    "# Set up operations so that they will occur sequentially\n",
    "data_augmentation = keras.Sequential(augmentations, name='data_augmentation')\n",
    "# Augment the training data examples\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44d87104-dc2f-4266-a71c-ad57588605c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    \"\"\"\n",
    "    Image Patch Extraction as a Layer extension\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size, num_patches):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "        \n",
    "    def call(self, images):\n",
    "        \"\"\"Apply the patching / sub-sampling of the images and create the sub-images\"\"\"\n",
    "        # Batch size is the first index of the shape [batch_size, image_height, image_width, image_channels]\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        # Generate the sub-regions of the image to feed to the network in pieces\n",
    "        patches = tf.image.extract_patches(images=images,\n",
    "                                           sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "                                           strides=[1, self.patch_size, self.patch_size, 1],\n",
    "                                           rates=[1, 1, 1, 1],\n",
    "                                           padding='VALID')\n",
    "        \n",
    "        patch_dims = patches.shape[-1]\n",
    "        # Reshape so that the image patches are sequenced\n",
    "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706fdb2-beff-447b-93da-13494764e959",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a78d1f-459c-45f5-bf35-040dba2f0118",
   "metadata": {},
   "source": [
    "### MLP-Mixer Model\n",
    "\n",
    "* The MLP-Mixer is an architecture based exclusively on multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
    "\n",
    "        One applied independently to image patches, which mixes the per-location features.\n",
    "        The other applied across patches (along channels), which mixes spatial information.\n",
    "        \n",
    "\n",
    "* This is similar to a depthwise separable convolution based model such as the Xception model, but with two chained dense transforms, no max pooling, and layer normalization instead of batch normalization.\n",
    "\n",
    "* https://arxiv.org/abs/2105.01601\n",
    "\n",
    "* The MLP-Mixer model tends to have much less number of parameters compared to convolutional and transformer-based models, which leads to less training and serving computational cost.\n",
    "\n",
    "* As mentioned in the MLP-Mixer paper, when pre-trained on large datasets, or with modern regularization schemes, the MLP-Mixer attains competitive scores to state-of-the-art models. You can obtain better results by increasing the embedding dimensions, increasing, increasing the number of mixer blocks, and training the model for longer. You may also try to increase the size of the input images and use different patch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d64d175-db0e-4af0-ae28-6f9e1979d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPMixerLayer(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 num_patches,\n",
    "                 hidden_units,\n",
    "                 dropout_rate,\n",
    "                 embedding_dim,\n",
    "                 *args,\n",
    "                 **kwargs):\n",
    "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create the first of the different blocks (sub-MLPs) input size=num_patches, output_size=num_patches\n",
    "        self.mlp1 = keras.Sequential([layers.Dense(units=num_patches),\n",
    "                                      tfa.layers.GELU(), # Gaussian Error Linear Unit\n",
    "                                      layers.Dense(units=num_patches),\n",
    "                                      layers.Dropout(rate=dropout_rate)])\n",
    "        \n",
    "        # Create the second of the different blocks input_size=num_blocks, output_size=embedding_dim\n",
    "        self.mlp2 = keras.Sequential([layers.Dense(units=num_patches),\n",
    "                                      tfa.layers.GELU(),\n",
    "                                      layers.Dense(units=embedding_dim),\n",
    "                                      layers.Dropout(rate=dropout_rate)])\n",
    "        # Normalize using LayerNorm so that there is no dependency on batch_size while reducing overfitting\n",
    "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Apply input normalization\n",
    "        x = self.normalize(inputs)\n",
    "        \n",
    "        # Transpose inputs\n",
    "        x_channels = tf.linalg.matrix_transpose(x)\n",
    "        \n",
    "        # Apply block1 to the input channels, each independently\n",
    "        mlp1_outputs = self.mlp1(x_channels)\n",
    "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
    "        # Add a skip-connection to allow strong input features to have additional input\n",
    "        x = mlp1_outputs + inputs\n",
    "        # Normalize Layers\n",
    "        x_patches = self.normalize(x)\n",
    "        mlp2_outputs = self.mlp2(x_patches)\n",
    "        # Skip Connection\n",
    "        x = x + mlp2_outputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc475c2d-1306-4033-91b2-9ee6eb52af2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "352/352 [==============================] - 277s 776ms/step - loss: 3.8682 - acc: 0.1100 - top5-acc: 0.3160 - val_loss: 3.4875 - val_acc: 0.1716 - val_top5-acc: 0.4352 - lr: 0.0050\n",
      "Epoch 2/5\n",
      "352/352 [==============================] - 228s 648ms/step - loss: 3.3913 - acc: 0.1850 - top5-acc: 0.4543 - val_loss: 3.3496 - val_acc: 0.2012 - val_top5-acc: 0.4880 - lr: 0.0050\n",
      "Epoch 3/5\n",
      "352/352 [==============================] - 239s 679ms/step - loss: 3.2107 - acc: 0.2181 - top5-acc: 0.5053 - val_loss: 3.1287 - val_acc: 0.2464 - val_top5-acc: 0.5328 - lr: 0.0050\n",
      "Epoch 4/5\n",
      "352/352 [==============================] - 246s 698ms/step - loss: 3.0622 - acc: 0.2446 - top5-acc: 0.5444 - val_loss: 2.8750 - val_acc: 0.2850 - val_top5-acc: 0.5914 - lr: 0.0050\n",
      "Epoch 5/5\n",
      "352/352 [==============================] - 314s 892ms/step - loss: 2.9180 - acc: 0.2742 - top5-acc: 0.5781 - val_loss: 2.8699 - val_acc: 0.2958 - val_top5-acc: 0.6024 - lr: 0.0050\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 2.8031 - acc: 0.3093 - top5-acc: 0.6211\n",
      "Test accuracy: 30.93%\n",
      "Test top 5 accuracy: 62.11%\n"
     ]
    }
   ],
   "source": [
    "mlpmixer_blocks = keras.Sequential([MLPMixerLayer(num_patches, embedding_dim, dropout_rate, embedding_dim) for _ in range(num_blocks)])\n",
    "learning_rate = 0.005\n",
    "mlpmixer_classifier = build_keras_classifier(mlpmixer_blocks)\n",
    "record = run_experiment(mlpmixer_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d4b656-9f8f-4b83-a4a4-a7bb07235697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5e8d382-aa5e-4359-9911-834669b7e1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'i', 'i', 'i']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e93298a-df8e-4a03-addb-36ef4b28af14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9f9cc-f422-404b-8518-d46da7290540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37457c4a-cae1-40b3-987c-df0187a34f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
